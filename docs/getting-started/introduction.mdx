---
title: Introduction
description: "OpenMind is building the Android for robots - open-source software that lets machines think, learn, and work together."
---


## What is OpenMind (OM1)
OpenMind (OM1) is an open-source operating system designed to run directly on your physical robot hardware, from quadrupeds to humanoids and custom builds. It provides the software foundation—the 'brains'—that enables your robot to perceive its environment, make decisions, and perform actions. While OM1 can also power digital AI agents, its primary focus is on bringing advanced AI capabilities to your physical machines."

For example, an AI agent built on OM1 can ingest data from multiple sources (the web, X/Twitter, cameras, and LIDAR) and can then Tweet and explore your house, shake your hand, or talk to you. In another example, with OM1, you can talk with OpenAI's `gpt-4o` and literally shake hands with it.

## Capabilities of OM1

<CardGroup cols={2}>
  <Card
    title=" Simple, modular architecture"
    icon="square-1"
  >
  Easy-to-understand, independent components that work together seamlessly.
   
  </Card>
   <Card
    title="All python "
    icon="square-2"
  >
  Independent modules that are easy maintain, and extend.
  </Card>
   <Card
    title="Easy to add new data inputs "
    icon="square-3"
  >
    Seamlessly integrate new data without major changes to the existing structure.
  </Card>
  <Card
    title="Easy to support new hardware "
    icon="square-4"
  >
   via plugins for API endpoints and specific robot hardware
  </Card>
  <Card
    title="Can be connected to: "
    icon="square-5"
  >
   `ROS2`, `Zenoh`, and `CycloneDDS`
  </Card>
  <Card
    title="Includes a simple web-based debug display "
    icon="square-6"
  >
   to watch the system work (`WebSim` at http://localhost:8000)
  </Card>
  <Card
    title="Preconfigured endpoints"
    icon="square-7"
  >
  for Voice-to-Speech, OpenAI's `gpt-4o`, DeepSeek, and multiple VLMs
  </Card>
  </CardGroup>